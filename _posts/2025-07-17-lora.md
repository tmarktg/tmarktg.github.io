---
layout: post
title: Drowning in AI Art LORAs, ComfyUI
subtitle: The Startup That Might Happen (Someday)
# cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thumb4.png
# share-img: /assets/img/path.jpg
tags: [software development]
author: Mark Truong
---

So very recently, I’ve fallen into the AI image generation rabbit hole.
(Sorry, artists — I swear I still love you.)

It started as curiosity, quickly turned into obsession, and somehow snowballed into startup brainstorming, prompt engineering marathons, and more time spent inside ComfyUI and FluxGym than I’d like to admit. If you’ve ever touched Stable Diffusion, CivitAI, or messed with LoRAs, you probably know the feeling.

## So, Why Am I Doing This?

A good friend of mine, Leo, an incredibly talented person with a portfolio worth checking out — https://www.leonardo-sullivan.com and I were bouncing around ideas for a potential startup (you know, the millionth one). This time, we had our sights set on a platform that uses AI-generated and animated art for children’s stories, particularly designed for kids with disabilities who struggle with focus.

Think:
📚 Interactive storybooks
🎨 AI-generated scenes
🧰 Treasure chest rewards
🎞️ Wan2.1 + Veo 3 style animation loops
…all backed by LoRA-trained models.

Yeah. We dream big.

⸻

## The Fun (and Pain) of the Stack

Here’s what I’ve been using so far:
	•	ComfyUI: For building workflows, prompting, and breaking my brain
	•	FluxGym: For training and benchmarking LoRAs (and yes, too much time wasted here)
	•	InvokeAI and ComfyUI: Swapping between these like a mad scientist testing which lab is cleaner
	•	Ultrarealistic LoRA project on CivitAI: A solid base for generating believable people

Trying to generate high-quality character images that can be animated, customized, and eventually dropped into a storybook flow takes a ridiculous amount of tinkering. Especially when you’re new to:
	•	Dataset structuring
	•	Parameter tuning
	•	LoRA training vs finetuning
	•	Prompting theory vs reality

If you’ve never tried training a LoRA on Flux, just know it’s like trying to pilot a spaceship when you barely know how to ride a bike. Kohya would’ve helped, but I skipped it, and now I’m paying the price.

## Will Any of This Make Money?

Great question.

With Veo 3, Runway, and the rise of AI-enhanced visual media, it feels like big companies are paving the way (or gatekeeping it, depending on your view). It’s easy to wonder: Is this a creative goldmine, or just a gold rush where the shovels are sold by OpenAI?

Still, the idea of generating AI illustrations for books that don’t have any — and selling those visuals to indie authors or publishers — is sticking with me. It’s practical. It solves a real gap. And it’s easier to market than “here’s a random LoRA I trained on my cat.”

## Where I’m At Now

Right now, I’m still:
	•	Supporting Leo's LoRA work
	•	Building hyperrealistic character pipelines
	•	Switching shamelessly between tools to benchmark outputs
	•	Trying to not let ComfyUI consume my soul

Honestly, I’ve learned a lot. Even if this doesn’t become a business, it’s been a wild ride into the future of art, storytelling, and assistive tech. And that alone has been worth the time.

If you’re in this space, let’s talk. I’d love to hear what you’re building, where you’re stuck, or what weird use case you’re chasing with LoRAs and AI art.

Otherwise… back to the Flux mines I go.
