---
layout: post
title: Drowning in AI Art LORAs, ComfyUI
subtitle: The Startup That Might Happen (Someday)
# cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thumb4.png
# share-img: /assets/img/path.jpg
tags: [software development]
author: Mark Truong
---

So very recently, Iâ€™ve fallen into the AI image generation rabbit hole.
(Sorry, artists â€” I swear I still love you.)

It started as curiosity, quickly turned into obsession, and somehow snowballed into startup brainstorming, prompt engineering marathons, and more time spent inside ComfyUI and FluxGym than Iâ€™d like to admit. If youâ€™ve ever touched Stable Diffusion, CivitAI, or messed with LoRAs, you probably know the feeling.

## So, Why Am I Doing This?

A good friend of mine, Leo, an incredibly talented person with a portfolio worth checking out â€” https://www.leonardo-sullivan.com and I were bouncing around ideas for a potential startup (you know, the millionth one). This time, we had our sights set on a platform that uses AI-generated and animated art for childrenâ€™s stories, particularly designed for kids with disabilities who struggle with focus.

Think:
ğŸ“š Interactive storybooks
ğŸ¨ AI-generated scenes
ğŸ§° Treasure chest rewards
ğŸï¸ Wan2.1 + Veo 3 style animation loops
â€¦all backed by LoRA-trained models.

Yeah. We dream big.

â¸»

## The Fun (and Pain) of the Stack

Hereâ€™s what Iâ€™ve been using so far:
	â€¢	ComfyUI: For building workflows, prompting, and breaking my brain
	â€¢	FluxGym: For training and benchmarking LoRAs (and yes, too much time wasted here)
	â€¢	InvokeAI and ComfyUI: Swapping between these like a mad scientist testing which lab is cleaner
	â€¢	Ultrarealistic LoRA project on CivitAI: A solid base for generating believable people

Trying to generate high-quality character images that can be animated, customized, and eventually dropped into a storybook flow takes a ridiculous amount of tinkering. Especially when youâ€™re new to:
	â€¢	Dataset structuring
	â€¢	Parameter tuning
	â€¢	LoRA training vs finetuning
	â€¢	Prompting theory vs reality

If youâ€™ve never tried training a LoRA on Flux, just know itâ€™s like trying to pilot a spaceship when you barely know how to ride a bike. Kohya wouldâ€™ve helped, but I skipped it, and now Iâ€™m paying the price.

## Will Any of This Make Money?

Great question.

With Veo 3, Runway, and the rise of AI-enhanced visual media, it feels like big companies are paving the way (or gatekeeping it, depending on your view). Itâ€™s easy to wonder: Is this a creative goldmine, or just a gold rush where the shovels are sold by OpenAI?

Still, the idea of generating AI illustrations for books that donâ€™t have any â€” and selling those visuals to indie authors or publishers â€” is sticking with me. Itâ€™s practical. It solves a real gap. And itâ€™s easier to market than â€œhereâ€™s a random LoRA I trained on my cat.â€

## Where Iâ€™m At Now

Right now, Iâ€™m still:
	â€¢	Supporting Leo's LoRA work
	â€¢	Building hyperrealistic character pipelines
	â€¢	Switching shamelessly between tools to benchmark outputs
	â€¢	Trying to not let ComfyUI consume my soul

Honestly, Iâ€™ve learned a lot. Even if this doesnâ€™t become a business, itâ€™s been a wild ride into the future of art, storytelling, and assistive tech. And that alone has been worth the time.

If youâ€™re in this space, letâ€™s talk. Iâ€™d love to hear what youâ€™re building, where youâ€™re stuck, or what weird use case youâ€™re chasing with LoRAs and AI art.

Otherwiseâ€¦ back to the Flux mines I go.
